人工智能探索与实践集成学习:基础与算法 PDF下载 周志华 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712139077
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712139077
<p>书名:人工智能探索与实践集成学习:基础与算法</p><p>作者:周志华</p><p>页数:224</p><p>定价:¥89.0</p><p>出版社:电子工业出版社</p><p>出版日期:2020-07-01</p><p>ISBN:9787121390777</p><p><h2>本书特色</h2></p>[<p>
《集成学习：基础与算法》是目前国内独本系统性阐述集成学习的著作。 <br/>集成学习的思路是通过结合多个学习器来解决问题，集成学习在实践中大获成功——人称“从业者应学应会的大杀器”之一。 <br/>化繁为简：将复杂的原理简化为易于理解的表达，通俗易懂； <br/>结构合理：兼具广度与深度。既阐述该领域的重要话题，又详释了重要算法的实现并辅以伪代码，更易上手； <br/>注重实践：阐述集成学习在多个领域的应用，如计算机视觉、医疗、信息安全和数据挖掘竞赛等； <br/>拓展阅读：提供丰富的参考资料，读者可按图索骥、自行深入学习； <br/>新手通过《集成学习：基础与算法》很容易理解并掌握集成学习的思路与精粹； <br/>老手通过《集成学习：基础与算法》能学会不少技巧并深化对集成学习的理论理解，更好地指导研究和实践。 
                                        </p>]<p><h2>内容简介</h2></p>[<p>集成学习方法是一类优选的机器学习方法，这类方法训练多个学习器并将它们结合起来解决一个问题，在实践中获得了巨大成功。全书分为三部分。部分主要介绍集成学习的背景知识；第二部分主要介绍集成学习方法的核心知识，包括Boosting、Bagging、Random Forests等经典算法，平均、投票和Stacking等模型和方法、相关理论分析工作，以及多样性度量和增强方面的进展。第三部分介绍集成学习方法的进阶议题，包括集成修剪、聚类集成和集成学习方法在半监督学习、主动学习、代价敏感学习、类别不平衡学习，以及提升可理解性方面的进展。此外，本书还在每章中的“拓展阅读”部分提供了相关的进阶内容。本书适合对集成学习方法感兴趣的研究人员、学生和实践者阅读。</p>]<p><h2>作者简介</h2></p>[<p>周志华，教授、南京大学计算机系主任、人工智能学院院长、校学术委员会委员。 <br/>欧洲科学院外籍院士，首位在人工智能相关五大主流国际学会ACM、AAAI、AAAS、IEEE、IAPR均当选为会士的华人学者。 <br/>中国计算机学会、中国人工智能学会会士。 <br/>曾获IEEE计算机学会Edward J. McCluskey技术成就奖、CCF王选奖等。 李楠，博士，毕业于南京大学计算机系机器学习与数据挖掘研究所(LAMDA)，师从周志华教授从事机器学习研究。 <br/>发表论文20余篇，并获国际数据挖掘竞赛冠军及最佳论文奖。 <br/>先后供职于阿里巴巴iDST/达摩院和微软亚洲互联网工程院，主要从事机器学习在互联网搜索、推荐和广告中的研究和应用工作。 <br/></p>]<p><h2>目录</h2></p>
第1章 绪 论     1 1.1 基本概念    1 1.2 常用学习算法    3 1.2.1 线性判别分析     3 1.2.2 决策树     4 1.2.3 神经网络   6 1.2.4 朴素贝叶斯      8 1.2.5 k-近邻     9 1.2.6 支持向量机和核方法     9 1.3 评估和对比     12 1.4 集成学习方法    14 1.5 集成学习方法的应用     16 1.6 拓展阅读    19  第2章 Boosting      21 2.1 Boosting 过程    21 2.2 AdaBoost 算法   22 2.3 说明性举例     26 2.4 理论探讨    29 2.4.1 基本分析   29 2.4.2 间隔解释   30 2.4.3 统计视角   32 2.5 多分类问题     35 2.6 容噪能力    37 2.7 拓展阅读    40  第3章 Bagging      43 3.1 两种集成范式    43 3.2 Bagging 算法    44 3.3 说明性举例     45 3.4 理论探讨    48 3.5 随机树集成     52 3.5.1 随机森林   52 3.5.2 随机化谱   55 3.5.3 随机森林用于密度估计    56 3.5.4 随机森林用于异常检测    58 3.6 拓展阅读    60  第4章 结合方法     61 4.1 结合带来的益处   61 4.2 均值法     62 4.2.1 简单平均法      62 4.2.2 加权平均法      63 4.3 投票法     65 4.3.1 绝对多数投票法       65 4.3.2 相对多数投票法       66 4.3.3 加权投票法      67 4.3.4 软投票法   68 4.3.5 理论探讨   70 4.4 学习结合法     76 4.4.1 Stacking     76 4.4.2 无限集成   78 4.5 其他结合方法    79 4.5.1 代数法     80 4.5.2 行为知识空间法       81 4.5.3 决策模板法      81 4.6 相关方法    82 4.6.1 纠错输出编码法       82 4.6.2 动态分类器选择法      85 4.6.3 混合专家模型     86 4.7 拓展阅读    87  第5章 多样性       91 5.1 集成多样性     91 5.2 误差分解    92 5.2.1 误差-分歧分解     92 5.2.2 偏差-方差-协方差分解    94 5.3 多样性度量     96 5.3.1 成对度量   96 5.3.2 非成对度量      97 5.3.3 小结和可视化     100 5.3.4 多样性度量的局限      101 5.4 信息论多样性    102 5.4.1 信息论和集成     102 5.4.2 交互信息多样性       103 5.4.3 多信息多样性     104 5.4.4 估计方法   105 5.5 多样性增强     106 5.6 拓展阅读    108  第6章 集成修剪     109 6.1 何谓集成修剪    109 6.2 多比全好    110 6.3 修剪方法分类    113 6.4 基于排序的修剪   114 6.5 基于聚类的修剪   117 6.6 基于优化的修剪   117 6.6.1 启发式优化修剪       118 6.6.2 数学规划修剪     118 6.6.3 概率修剪   121 6.7 拓展阅读    122  第7章 聚类集成     125 7.1 聚类      125 7.1.1 聚类方法   125 7.1.2 聚类评估   127 7.1.3 为什么要做聚类集成     129 7.2 聚类集成方法分类      130 7.3 基于相似度的方法      132 7.4 基于图的方法    133 7.5 基于重标记的方法      136 7.6 基于变换的方法   140 7.7 拓展阅读    143  第8章 进阶议题     145 8.1 半监督学习     145 8.1.1 未标记数据的效用      145 8.1.2 半监督学习的集成学习方法     146 8.2 主动学习    151 8.2.1 人为介入的效用       151 8.2.2 基于集成的主动学习     152 8.3 代价敏感学习    153 8.3.1 不均等代价下的学习     153 8.3.2 代价敏感学习的集成方法      154 8.4 类别不平衡学习   158 8.4.1 类别不平衡      158 8.4.2 类别不平衡学习的性能评估     160 8.4.3 类别不平衡学习的集成方法     163 8.5 提升可解释性    166 8.5.1 集成约简   166 8.5.2 规则抽取   167 8.5.3 可视化     168 8.6 未来的研究方向   169 8.7 拓展阅读    171 参考文献        173 索引        203 
