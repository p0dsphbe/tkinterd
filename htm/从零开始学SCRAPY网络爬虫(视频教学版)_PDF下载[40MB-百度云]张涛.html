从零开始学SCRAPY网络爬虫(视频教学版) PDF下载 张涛 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711163474
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711163474
<p>书名:从零开始学SCRAPY网络爬虫(视频教学版)</p><p>作者:张涛</p><p>页数:283</p><p>定价:¥99.0</p><p>出版社:机械工业出版社</p><p>出版日期:2018-03-01</p><p>ISBN:9787111634744</p><p><h2>本书特色</h2></p>[<p>
《从零开始学Scrapy网络爬虫》从零开始，循序渐进地介绍了目前流行的网络爬虫框架Scrapy。即使你没有任何编程基础，阅读《从零开始学Scrapy网络爬虫》也不会有压力，因为书中有针对性地介绍了Python编程技术。另外，《从零开始学Scrapy网络爬虫》在讲解过程中以案例为导向，通过对案例的不断迭代、优化，让读者加深对知识的理解，并通过14个项目案例，提高读者解决实际问题的能力。
《从零开始学Scrapy网络爬虫》共13章。其中，第1～4章为基础篇，介绍了Python基础、网络爬虫基础、Scrapy框架及基本的爬虫功能。第5～10章为进阶篇，介绍了如何将爬虫数据存储于MySQL、MongoDB和Redis数据库中；如何实现异步AJAX数据的爬取；如何使用Selenium和Splash实现动态网站的爬取；如何实现模拟登录功能；如何突破反爬虫技术，以及如何实现文件和图片的下载。第11~13章为高级篇，介绍了使用Scrapy-Redis实现分布式爬虫；使用Scrapyd和Docker部署分布式爬虫；使用Gerapy管理分布式爬虫，并实现了一个抢票软件的综合项目。
《从零开始学Scrapy网络爬虫》适合爬虫初学者、爱好者及高校相关专业的学生阅读，也适合数据爬虫工程师作为参考读物，同时还适合各大院校和培训机构作为教材使用。
教学PPT
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书从零开始，循序渐进地介绍了目前*流行的网络爬虫框架Scrapy。本书共13章。其中~4章为基础篇，介绍了Python基础、网络爬虫基础、Scrapy框架及基本的爬虫功能。第5~10章为进阶篇，介绍了如何将爬虫数据存储于MySQL、MongoDB和Redis数据库中；如何实现异步的Ajax数据的爬取；如何使用Selenium和Splash实现动态网站的爬取；如何实现模拟登录功能；如何突破反爬虫技术，以及如何实现文件和图片的下载。1~13章为不错篇，介绍了使用Scrapy-Redis实现分布式爬虫；使用Scrapyd和Docker部署分布式爬虫；使用Gerapy管理分布式爬虫，并实现了一个抢票软件的综合项目。本书适合爬虫初学者、爬虫爱好者及高校相关学生，也适合数据爬虫工程师作为参考读物，同时也适合各大院校和培训机构作为教材使用。</p>]<p><h2>作者简介</h2></p>[<p>张涛  毕业于中国科学技术大学，获硕士学位。目前在科大讯飞从事人工智能教育培训与研究。加入科大讯飞之前，曾经在知名日资企业任职研发经理，负责日本大型证券系统的设计与开发。有7年大学课程改革与教学经验，主要研究方向为Python网络爬虫、数据分析和机器学习。</p>]<p><h2>目录</h2></p>
    第1篇  基础篇
第1章  Python基础 2
1.1  Python简介 2
1.1.1  Python简史 2
1.1.2  搭建Python环境 3
1.1.3  安装PyCharm集成开发环境 6
1.2  Python基本语法 7
1.2.1  基本数据类型和运算 7
1.2.2  运算符和表达式 8
1.2.3  条件判断语句 9
1.2.4  循环语句 10
1.2.5  字符串 12
1.3  Python内置数据结构 14
1.3.1  列表 15
1.3.2  字典 16
1.3.3  元组 17
1.3.4  遍历对象集合 17
1.4  Python模块化设计 18
1.4.1  函数 18
1.4.2  迭代器（iterator） 20
1.4.3  生成器（Generator） 20
1.4.4  类和对象 22
1.4.5  文件与异常 23
1.5  本章小结 25
第2章  网络爬虫基础 26
2.1  HTTP基本原理 26
2.1.1  URL介绍 27
2.1.2  HTTP和HTTPS协议 27
2.1.3  HTTP请求（Request） 27
2.1.4  HTTP响应（Response） 30
2.2  网页基础 32
2.2.1  HTML文档 33
2.2.2  网页的结构 33
2.2.3  节点树及节点之间的关系 34
2.3  使用XPath提取网页信息 36
2.3.1  XPath介绍 36
2.3.2  XPath常用路径表达式 36
2.3.3  XPath带谓语的路径表达式 39
2.4  本章小结 40
第3章  Scrapy框架介绍 41
3.1  网络爬虫原理 41
3.1.1  爬虫执行的流程 41
3.2  Scrapy框架结构及执行流程 42
3.2.1  Scrapy框架结构 42
3.2.2  Scrapy执行流程 44
3.3  Scrapy安装 44
3.3.1  使用pip安装Scrapy 44
3.3.2  常见安装错误 45
3.3.3  验证安装 46
3.4  **个网络爬虫 46
3.4.1  需求分析 46
3.4.2  创建项目 47
3.4.3  分析页面 48
3.4.4  实现Spider爬虫功能 49
3.4.5  运行爬虫 50
3.4.6  常见问题 51
3.5  本章小结 52
第4章  Scrapy网络爬虫基础 53
4.1  使用Spider提取数据 53
4.1.1  Spider组件介绍 53
4.1.2  重写start_requests()方法 55
4.1.3  Request对象 57
4.1.4  使用选择器提取数据 58
4.1.5  Response对象与XPath 59
4.1.6  Response对象与CSS 61
4.1.7  进一步了解Response对象 62
4.1.8  多页数据的爬取 63
4.2  使用Item封装数据 64
4.2.1  定义Item和Field 65
4.2.2  使用ItemLoader填充容器 66
4.3  使用Pipeline处理数据 69
4.3.1  Item Pipeline介绍 70
4.3.2  编写自己的Item Pipeline 70
4.3.3  启用Item Pipeline 71
4.3.4  多个Item Pipeline 71
4.3.5  保存为其他类型文件 72
4.4  项目案例：爬取链家网二手房信息 75
4.4.1  项目需求 75
4.4.2  技术分析 76
4.4.3  代码实现及解析 77
4.5  本章小结 85
第2篇  进阶篇
第5章  数据库存储 88
5.1  MySQL数据库 88
5.1.1  关系型数据库概述 88
5.1.2  下载和安装MySQL数据库 88
5.1.3  数据库管理工具Navicat 92
5.1.4  Python访问MySQL数据库 94
5.1.5  项目案例 97
5.2  MongoDB数据库 100
5.2.1  NoSQL概述 100
5.2.2  MongoDB介绍 100
5.2.3  MongoDB的下载和安装 101
5.2.4  Python访问MongoDB数据库 102
5.2.5  项目案例 108
5.3  Redis数据库 111
5.3.1  Redis的下载和安装 111
5.3.2  Python访问Redis 113
5.3.3  项目案例 118
5.4  本章小结 121
第6章  JavaScript与AJAX数据爬取 122
6.1  JavaScript简介 122
6.2  项目案例：爬取QQ音乐榜单歌曲 122
6.2.1  项目需求 122
6.2.2  技术分析 123
6.2.3  代码实现及解析 126
6.2.4  更常见的动态网页 128
6.3  AJAX简介 129
6.4  项目案例：爬取豆瓣电影信息 130
6.4.1  项目需求 130
6.4.2  技术分析 130
6.4.3  代码实现及解析 133
6.5  本章小结 135
第7章  动态渲染页面的爬取 136
7.1  Selenium实现动态页面爬取 136
7.1.1  Selenium安装 136
7.1.2  Selenium简单实现 137
7.1.3  Selenium语法 138
7.2  项目案例：爬取今日头条热点新闻 145
7.2.1  项目需求 145
7.2.2  技术分析 145
7.2.3  代码实现及解析 147
7.3  Splash实现动态页面爬取 151
7.3.1  Splash介绍 151
7.3.2  Splash环境搭建 152
7.3.3  Splash模块介绍 156
7.4  项目案例：爬取一号店中的iPhone手机信息 162
7.4.1  项目需求 162
7.4.2  技术分析 163
7.4.3  代码实现及解析 165
7.5  本章小结 168
第8章  模拟登录 169
8.1  模拟登录解析 169
8.1.1  登录过程解析 169
8.1.2  模拟登录的实现 171
8.2  验证码识别 174
8.2.1  使用OCR识别验证码 174
8.2.2  处理复杂验证码 176
8.2.3  五花八门的验证码 177
8.3  Cookie自动登录 177
8.3.1  Cookie介绍 178
8.3.2  获取Cookie的库—browsercookie 179
8.4  项目案例：爬取起点中文网某用户的书架信息 180
8.4.1  项目需求 180
8.4.2  技术分析 180
8.4.3  代码实现及解析 182
8.5  本章小结 184
第9章  突破反爬虫技术 185
9.1  反爬虫技术及突破措施 185
9.2  伪装成不同的浏览器 187
9.2.1  UserAgentMiddleware中间件介绍 187
9.2.2  实现伪装成随机浏览器 188
9.2.3  更简单的方法 191
9.3  使用HTTP代理服务器 192
9.3.1  HTTP代理服务器 192
9.3.2  获取免费代理 193
9.3.3  实现随机代理 199
9.4  本章小结 202
第10章  文件和图片下载 203
10.1  文件下载 203
10.1.1  FilesPipeline执行流程 203
10.2  项目案例：爬取seaborn案例源文件 204
10.2.1  项目需求 204
10.2.2  技术分析 206
10.2.3  代码实现及解析 206
10.2.4  更多功能 211
10.3  图片下载 212
10.4  项目案例：爬取摄图网图片 213
10.4.1  项目需求 213
10.4.2  技术分析 215
10.4.3  代码实现及解析 215
10.5  本章小结 221
第3篇  高级篇
第11章  Scrapy-Redis实现分布式爬虫 224
11.1  分布式爬虫原理 224
11.2  Scrapy-Redis实现分布式爬虫分析 225
11.2.1  实现分布式爬虫思路 225
11.2.2  Scrapy-Redis代码解析 226
11.2.3  分布式爬虫功能配置 231
11.3  项目案例：分布式爬虫爬取摄图网图片 233
11.3.1  技术分析 233
11.3.2  代码实现及解析 234
11.4  本章小结 237
第12章  Scrapyd部署分布式爬虫 238
12.1  使用Scrapyd部署分布式爬虫 238
12.1.1  Scrapyd的安装及运行 238
12.1.2  Scrapyd功能介绍 241
12.2  使用Scrapyd-Client批量部署 244
12.3  使用Docker部署分布式爬虫 248
12.4  使用Gerapy管理分布式爬虫 253
12.5  本章小结 258
第13章  综合项目：抢票软件的实现 259
13.1  项目需求 259
13.2  技术分析 262
13.3  项目实现及解析 263
13.3.1  搭建Scrapy项目框架 263
13.3.2  实现获取站点信息的爬虫 264
13.3.3  实现站点处理类 266
13.3.4  实现购票类 267
13.3.5  实现购票功能 280
13.3.6  运行项目 282
13.3.7  优化项目 282
13.4  本章小结 283
